<resources>
    <string name="app_name">Numerical Tasks Solver</string>

    <string name="gauss_classic_method_description"> \n* In mathematics, Gaussian elimination, also known as row reduction, is an algorithm for solving systems of linear equations.
 \n* It consists of a sequence of operations performed on the corresponding matrix of coefficients.
 \n* This is a method of successive elimination of variables, when, with the help of elementary transformations,
 \n* the system of equations is reduced to an equivalent system of a triangular type,
 \n* from which all the variables of the system are found sequentially, starting from the last (by number).
 \n* This method is based on forward and backward sweeps.
 \n*
 \n* Asymptotic complexity: O(n^3).
    </string>

    <string name="thomas_method_description"> \n* In numerical linear algebra, the tridiagonal matrix algorithm, also known as the Thomas algorithm (named after Llewellyn Thomas),
 \n* is a simplified form of Gaussian elimination that can be used to solve tridiagonal systems of equations.
 \n* This method is based on forward and backward sweeps.
 \n*
 \n* Tridiagonal matrix is a band matrix that has nonzero elements on the main diagonal, the first diagonal below this, and the first diagonal above the main diagonal only.
 \n*
 \n* Asymptotic complexity: O(n) or O(n^2). O(n^2) is default, beacause by default this method implementation does validation of input matrix A, which must be tridiagonal.
 \n* You can get the required original asymptotic complexity O(n) by disabling validation, if you need to increase performance:
 \n* you can use increasePerformanceByIgnoringInputDataChecking flag by true, and validation will be disabled.
 \n* But you yourself have to take care of the correctness of the input data.
    </string>

    <string name="jacobi_method_description"> \n* In numerical linear algebra, the Jacobi method is an iterative algorithm for determining the solutions of a strictly diagonally dominant system of linear equations.
 \n* Each diagonal element is solved for, and an approximate value is plugged in. The process is then iterated until it converges.
 \n* This algorithm is a stripped-down version of the Jacobi transformation method of matrix diagonalization.
 \n* The method is named after Carl Gustav Jacob Jacobi.
 \n*
 \n* Asymptotic complexity: O(n^3)
    </string>

    <string name="seidel_method_description"> \n* In numerical linear algebra, the Gaussâ€“Seidel method, also known as the Liebmann method or the method of successive displacement,
 \n* is an iterative method used to solve a system of linear equations and is similar to the [JacobiMethod].
 \n* The Gauss-Seidel method can be considered as a modification of the Jacobi method, which, as practice shows,
 \n* requires approximately half the number of iterations compared to the Jacobi method.
 \n* Though it can be applied to any matrix with non-zero elements on the diagonals,
 \n* convergence is only guaranteed if the matrix is either strictly diagonally dominant, or symmetric and positive definite.
 \n*
 \n* Asymptotic complexity: O(n^3)
    </string>


</resources>